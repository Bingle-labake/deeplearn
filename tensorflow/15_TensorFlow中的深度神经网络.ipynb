{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15_TensorFlow中的深度神经网络.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingle-labake/deeplearn/blob/master/tensorflow/15_TensorFlow%E4%B8%AD%E7%9A%84%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SYEYnut3J-j5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###TensorFlow 中的深度神经网络\n",
        "你已经学过了如何用 TensorFlow 构建一个逻辑分类器。现在你会学到如何用逻辑分类器来构建一个深度神经网络。\n",
        "\n",
        "###详细指导\n",
        "接下来我们看看如何用 TensorFlow 来构建一个分类器来对 MNIST 数字进行分类。如果你要在自己电脑上跑这个代码，[文件](https://s3.cn-north-1.amazonaws.com.cn/static-documents/nd101/DLND+documents/multilayer-perceptron.zip)在这儿。你可以在[Aymeric Damien 的 GitHub repository](https://github.com/aymericdamien/TensorFlow-Examples)里找到更多的 TensorFlow 的例子。\n",
        "\n",
        "##代码\n",
        "##TensorFlow MNIST"
      ]
    },
    {
      "metadata": {
        "id": "UhQsmAutJzh5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0IR8od-0KbXZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "你可以使用 TensorFlow 提供的 MNIST 数据集，他把分批和 one-hot 编码（独热码）都帮你处理好了。\n",
        "\n",
        "###学习参数 Learning Parameters"
      ]
    },
    {
      "metadata": {
        "id": "-GW_-uSFKjOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 参数 Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 20\n",
        "batch_size = 128  # 如果没有足够内存，可以降低 batch size\n",
        "display_step = 1\n",
        "\n",
        "n_input = 784  # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10  # MNIST total classes (0-9 digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "votyRvmHKnXq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "这里的关注点是多层神经网络的架构，不是调参，所以这里直接给你了学习的参数。\n",
        "\n",
        "###隐藏层参数 Hidden Layer Parameters"
      ]
    },
    {
      "metadata": {
        "id": "JCy1VH2IKvkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden_layer = 256 # layer number of features 特征的层数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRK2EbOSK0J6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "n_hidden_layer 决定了神经网络隐藏层的大小。也被称作层的宽度。\n",
        "\n",
        "###权重和偏置项 Weights and Biases"
      ]
    },
    {
      "metadata": {
        "id": "eXQfGPmyK5yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "# 层权重和偏置项的储存\n",
        "weights = {\n",
        "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9u_fyhGQK9NC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "深度神经网络有多个层，每个层有自己的权重和偏置项。'hidden_layer' 的权重和偏置项只属于隐藏层（hidden_layer）， 'out' 的权重和偏置项只属于输出层（output layer）。如果神经网络比这更深，那每一层都有权重和偏置项。\n",
        "\n",
        "###输入 Input\n"
      ]
    },
    {
      "metadata": {
        "id": "1oMqJJg7LFAz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "x_flat = tf.reshape(x, [-1, n_input])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyG_WNcJLJHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST 数据集是由 28px * 28px 单通道图片组成。tf.reshape()函数把 28px * 28px 的矩阵转换成了 784px * 1px 的单行向量 x。\n",
        "\n",
        "###多层感知器 Multilayer Perceptron\n",
        "![替代文字](https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580fe8f8_multi-layer/multi-layer.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9uvYQFN4LUM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hidden layer with RELU activation\n",
        "# ReLU作为隐藏层激活函数\n",
        "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']),\\\n",
        "    biases['hidden_layer'])\n",
        "layer_1 = tf.nn.relu(layer_1)\n",
        "# Output layer with linear activation\n",
        "# 输出层的线性激活函数\n",
        "logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7uUDaF8LV3z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "你之前已经见过 tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])，也就是 xw + b。把线性函数与 ReLU 组合在一起，形成一个2层网络。\n",
        "\n",
        "###优化器 Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "44pMj9i4Ld7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "# 定义误差值和优化器\n",
        "cost = tf.reduce_mean(\\\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
        "    .minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "33JgeuLyLhk8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "这跟 Intro to TensorFlow lab 里用到的优化技术一样。\n",
        "\n",
        "###Session"
      ]
    },
    {
      "metadata": {
        "id": "uZ8DKYUULj90",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initializing the variables\n",
        "# 初始化变量\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "# 启动图\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # Training cycle\n",
        "    # 训练循环\n",
        "    for epoch in range(training_epochs):\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\n",
        "        # Loop over all batches\n",
        "        # 遍历所有 batch\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            # 运行优化器进行反向传导、计算 cost（获取 loss 值）\n",
        "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFsSU-JaLpYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow 中的 MNIST 库提供了分批接收数据的能力。调用mnist.train.next_batch()函数返回训练数据的一个子集。\n",
        "\n",
        "###深度神经网络\n",
        "![替代文字](https://d17h27t6h515a5.cloudfront.net/topher/2016/October/58100bfd_layers/layers.png)\n",
        "就是这样！从一层到两层很简单。向网络中添加更多层，可以让你解决更复杂的问题。"
      ]
    }
  ]
}