{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_3_7_weight_initialization.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingle-labake/deeplearn/blob/master/3/3/3_3_7_weight_initialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGwgFgFpuoXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1KkjZJvu-iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7_UNDkrvCuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/colab/3_3_7/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjY3Mr5mSInv",
        "colab_type": "text"
      },
      "source": [
        "##æƒé‡åˆå§‹åŒ–\n",
        "åœ¨è¿™èŠ‚è¯¾ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ä¸ºç¥ç»ç½‘ç»œè®¾ç½®åˆé€‚çš„åˆå§‹æƒé‡ã€‚æƒé‡åˆå§‹åŒ–åªå‘ç”Ÿä¸€æ¬¡ï¼Œå‘ç”Ÿåœ¨æ¨¡å‹åˆ›å»ºæ—¶åŠè®­ç»ƒä¹‹å‰ã€‚åˆé€‚çš„åˆå§‹æƒé‡ä½¿ç¥ç»ç½‘ç»œæ›´æ¥è¿‘æœ€ä½³æ¨¡å‹ï¼Œä»è€Œä½¿ç¥ç»ç½‘ç»œèƒ½æ›´å¿«åœ°è¾¾åˆ°æœ€ä½³æ¨¡å‹ã€‚\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](http://p7.qhimg.com/t016182dd0b44c10446.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH95GdNFSq2_",
        "colab_type": "text"
      },
      "source": [
        "##åˆå§‹æƒé‡å’Œè§‚å¯Ÿè®­ç»ƒæŸå¤±\n",
        "è¦æŸ¥çœ‹ä¸åŒæƒé‡çš„æ•ˆæœï¼Œæˆ‘ä»¬å°†ç”¨ç›¸åŒçš„æ•°æ®é›†å’Œç¥ç»ç½‘ç»œè¿›è¡Œæµ‹è¯•ã€‚è¿™æ ·æˆ‘ä»¬å°±çŸ¥é“æ¨¡å‹è¡Œä¸ºçš„ä»»ä½•å˜åŒ–æ˜¯ç”±æƒé‡å¯¼è‡´çš„ï¼Œè€Œä¸æ˜¯æ•°æ®å˜åŒ–æˆ–æ¨¡å‹æ¶æ„å¯¼è‡´çš„ã€‚\n",
        "\n",
        "\n",
        "> æˆ‘ä»¬å°†å®ä¾‹åŒ–è‡³å°‘ä¸¤ä¸ªç›¸åŒçš„æ¨¡å‹ï¼Œå¹¶ä¸”å…·æœ‰ä¸åŒçš„åˆå§‹æƒé‡ï¼Œçœ‹çœ‹è®­ç»ƒæŸå¤±æ˜¯å¦‚ä½•é™ä½çš„ï¼Œå¦‚ä»¥ä¸‹ç¤ºä¾‹æ‰€ç¤ºã€‚\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](http://p2.qhimg.com/t012166aff403cb417b.png)\n",
        "\n",
        "\n",
        "æœ‰æ—¶å€™è®­ç»ƒæŸå¤±çš„å·®å¼‚å°†å¾ˆå¤§ï¼Œæœ‰æ—¶å€™æŸäº›æƒé‡å¸¦æ¥çš„æ”¹è¿›å¾ˆå°ã€‚\n",
        "\n",
        "##æ•°æ®é›†å’Œæ¨¡å‹\n",
        "\n",
        "æˆ‘ä»¬å°†è®­ç»ƒ MLP å¯¹ Fashion-MNIST æ•°æ®åº“ä¸­çš„å›¾åƒè¿›è¡Œåˆ†ç±»ï¼Œæ¼”ç¤ºä¸åŒåˆå§‹æƒé‡çš„å½±å“ã€‚æ³¨æ„ï¼ŒFashion MNIST æ•°æ®é›†åŒ…å«æœé¥°ç±»å›¾åƒï¼›classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']ã€‚å›¾åƒå·²æ ‡å‡†åŒ–ï¼Œå› æ­¤åƒç´ å€¼èŒƒå›´æ˜¯ [0.0 - 1.0)ã€‚è¯·è¿è¡Œä»¥ä¸‹å•å…ƒæ ¼ï¼Œä»¥ä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†ã€‚\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "####ç»ƒä¹ \n",
        "\n",
        "[æ­£æ€åˆ†å¸ƒç»ƒä¹ ä»£ç çš„é“¾æ¥](https://)\n",
        "\n",
        "###å¯¼å…¥åº“å¹¶åŠ è½½[æ•°æ®](https://pytorch.org/docs/stable/torchvision/datasets.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV07QrSXRysx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 100\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.FashionMNIST(root='data', train=True,\n",
        "                                   download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='data', train=False,\n",
        "                                  download=True, transform=transform)\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)\n",
        "\n",
        "# specify the image classes\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOriZHrNTbIl",
        "colab_type": "text"
      },
      "source": [
        "###å¯è§†åŒ–ä¸€äº›è®­ç»ƒæ•°æ®"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veUnINUkUfFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "    \n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucTfq6jKUmMO",
        "colab_type": "text"
      },
      "source": [
        "##**å®šä¹‰æ¨¡å‹æ¶æ„**\n",
        "æˆ‘ä»¬å®šä¹‰äº†ç”¨äºåˆ†ç±»æ•°æ®é›†çš„ MLPã€‚\n",
        "\n",
        "###**ç¥ç»ç½‘ç»œ**\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](http://p1.qhimg.com/t01bd315afad7399ce7.png)\n",
        "\n",
        "\n",
        "*   è¯¥ MLP æœ‰ 3 å±‚ï¼Œéšè—å±‚çš„å¤§å°ä¸º 256 å’Œ 128ã€‚\n",
        "*   è¯¥ MLP æ¥å—æ‰å¹³åŒ–å›¾åƒï¼ˆé•¿ä¸º 784 çš„å‘é‡ï¼‰ï¼Œå¹¶ç”Ÿæˆ 10 ä¸ªç±»åˆ«åˆ†æ•°ã€‚\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "æˆ‘ä»¬å°†ç”¨è¿™ä¸ª 3 å±‚ç¥ç»ç½‘ç»œæµ‹è¯•ä¸åŒåˆå§‹æƒé‡çš„æ•ˆæœï¼Œè¯¥ç½‘ç»œä½¿ç”¨çš„æ˜¯ ReLU æ¿€æ´»å‡½æ•°å’Œ Adam ä¼˜åŒ–å™¨ã€‚\n",
        "\n",
        "è¿™é‡Œæåˆ°çš„ç»éªŒé€‚ç”¨äºåŒ…å«ä¸åŒæ¿€æ´»å‡½æ•°å’Œä¼˜åŒ–å™¨çš„å…¶ä»–ç¥ç»ç½‘ç»œã€‚\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##**åˆå§‹åŒ–æƒé‡**\n",
        "æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æŸäº›åˆå§‹æƒé‡ã€‚\n",
        "\n",
        "###**å…¨ä¸º 0 å’Œ 1**\n",
        "å¦‚æœä½ çŸ¥é“Occam's razorå®šå¾‹ï¼Œä½ å¯èƒ½è®¤ä¸ºå°†æ‰€æœ‰æƒé‡è®¾ä¸º 0 æˆ– 1 æ˜¯æœ€ä½³ç­–ç•¥ã€‚ä½†äº‹å®å¹¶éå¦‚æ­¤ã€‚\n",
        "\n",
        "å¦‚æœæ‰€æœ‰æƒé‡ä¸€æ ·ï¼Œæ¯ä¸ªå±‚çº§çš„æ‰€æœ‰ç¥ç»å…ƒéƒ½å°†ç”Ÿæˆç›¸åŒçš„è¾“å‡ºã€‚è¿™æ ·å°±å¾ˆéš¾åˆ¤æ–­è¦è°ƒæ•´å“ªäº›æƒé‡ã€‚\n",
        "\n",
        "æˆ‘ä»¬å®šä¹‰ä¸¤ä¸ªæ¨¡å‹å¹¶å°†æƒé‡å…¨è®¾ä¸º 1 æˆ– 0ï¼Œæ¯”è¾ƒè¿™ä¸¤ç§æ¨¡å‹çš„æŸå¤±\n",
        "\n",
        "ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ PyTorch çš„nn.init ç”¨å¸¸é‡æƒé‡åˆå§‹åŒ–æ¯ä¸ªçº¿æ€§å±‚çº§ã€‚init åº“æä¾›äº†å¤§é‡æƒ\n",
        "\n",
        "é‡åˆå§‹åŒ–å‡½æ•°ï¼Œè®©ä½ èƒ½å¤Ÿæ ¹æ®å±‚çº§ç±»å‹åˆå§‹åŒ–æ¯ä¸ªå±‚çº§çš„æƒé‡ã€‚\n",
        "\n",
        "åœ¨ä¸‹é¢çš„æƒ…å½¢ä¸­ï¼Œæˆ‘ä»¬æŸ¥çœ‹æ¨¡å‹é‡Œçš„æ¯ä¸ªå±‚çº§/æ¨¡å—ã€‚å¦‚æœæ˜¯çº¿æ€§å±‚çº§ï¼ˆè¿™ä¸ª MLP çš„æ‰€æœ‰ä¸‰\n",
        "\n",
        "ä¸ªå±‚çº§éƒ½æ˜¯çº¿æ€§å±‚çº§ï¼‰ï¼Œåˆ™å°†è¿™äº›å±‚çº§çš„æƒé‡åˆå§‹åŒ–ä¸º constant_weightï¼Œåå·®ä¸º 0ï¼Œä»£ç \n",
        "\n",
        "å¦‚ä¸‹æ‰€ç¤ºï¼š\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "if isinstance(m, nn.Linear): nn.init.constant_(m.weight, constant_weight) nn.init.constant_(m.bias, 0)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLA3zySlVpYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the NN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, hidden_1=256, hidden_2=128, constant_weight=None):\n",
        "        super(Net, self).__init__()\n",
        "        # linear layer (784 -> hidden_1)\n",
        "        self.fc1 = nn.Linear(28 * 28, hidden_1)\n",
        "        # linear layer (hidden_1 -> hidden_2)\n",
        "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
        "        # linear layer (hidden_2 -> 10)\n",
        "        self.fc3 = nn.Linear(hidden_2, 10)\n",
        "        # dropout layer (p=0.2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        # initialize the weights to a specified, constant value\n",
        "        if(constant_weight is not None):\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.constant_(m.weight, constant_weight)\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "            \n",
        "    def forward(self, x):\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add output layer\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIBBwJhtV1Su",
        "colab_type": "text"
      },
      "source": [
        "##**æ¯”è¾ƒæ¨¡å‹è¡Œä¸º**\n",
        "ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨ helpers.compare_init_weights æ¯”è¾ƒåœ¨ä¸Šé¢å®šä¹‰çš„ä¸¤ä¸ªæ¨¡å‹ model_0 å’Œ model_1 çš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±ã€‚æ­¤å‡½æ•°çš„è¾“å…¥å‚æ•°æ˜¯æ¨¡å‹åˆ—è¡¨ï¼ˆæ¯ä¸ªå…·æœ‰ä¸åŒçš„åˆå§‹æƒé‡ï¼‰ã€è¦ç”Ÿæˆçš„å›¾å½¢çš„åç§°ï¼Œä»¥åŠè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†åŠ è½½å™¨ã€‚å¯¹äºæ¯ä¸ªç»™å®šæ¨¡å‹ï¼Œå®ƒå°†ç»˜åˆ¶å‰ 100 æ‰¹çš„è®­ç»ƒæŸå¤±ï¼Œå¹¶è¾“å‡º 2 ä¸ªè®­ç»ƒå‘¨æœŸåçš„éªŒè¯å‡†ç¡®ç‡ã€‚æ³¨æ„ï¼šå¦‚æœæ‰¹æ¬¡å¤§å°å¾ˆå°ï¼Œåˆ™å¯èƒ½éœ€è¦å¢åŠ å‘¨æœŸæ•°ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ¯”è¾ƒæ¨¡å‹åœ¨è§‚å¯Ÿå‡ ç™¾å¼ å›¾åƒä¹‹åçš„è¡Œä¸ºã€‚\n",
        "\n",
        "\n",
        "æˆ‘ä»¬ç»˜å‡ºå‰ 100 æ‰¹çš„æŸå¤±ï¼Œä»¥ä¾¿æ›´å¥½åœ°åˆ¤æ–­å“ªç§æ¨¡å‹æƒé‡åœ¨è®­ç»ƒå¼€å§‹æ—¶æ•ˆæœæ›´å¥½ã€‚**å»ºè®®æŸ¥çœ‹ helpers.py ä¸­çš„ä»£ç ï¼Œè¯¦ç»†äº†è§£æ¨¡å‹æ˜¯å¦‚ä½•è®­ç»ƒã€éªŒè¯å’Œæ¯”è¾ƒçš„ã€‚**\n",
        "\n",
        "\n",
        "è¯·è¿è¡Œä»¥ä¸‹å•å…ƒæ ¼ï¼Œçœ‹çœ‹æƒé‡å…¨ä¸º 0 å’Œå…¨ä¸º 1 çš„å·®åˆ«ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bC5NZmeV_Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize two NN's with 0 and 1 constant weights\n",
        "model_0 = Net(constant_weight=0)\n",
        "model_1 = Net(constant_weight=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBqws1-7WEKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import helpers\n",
        "\n",
        "# put them in list form to compare\n",
        "model_list = [(model_0, 'All Zeros'),\n",
        "              (model_1, 'All Ones')]\n",
        "\n",
        "\n",
        "# plot the loss over the first 100 batches\n",
        "helpers.compare_init_weights(model_list, \n",
        "                             'All Zeros vs All Ones', \n",
        "                             train_loader,\n",
        "                             valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlPub0GAwVFA",
        "colab_type": "text"
      },
      "source": [
        "å¯ä»¥çœ‹å‡ºï¼Œå¯¹äºå…¨ä¸º 0 å’Œ 1 æ¥è¯´ï¼Œå‡†ç¡®ç‡éƒ½å’ŒçŒœæµ‹ç»“æœå·®ä¸å¤šï¼Œçº¦ä¸º 10%\n",
        "\n",
        "ç¥ç»ç½‘ç»œå¾ˆéš¾åˆ¤æ–­å“ªäº›æƒé‡éœ€è¦æ›´æ”¹ï¼Œå› ä¸ºæ¯ä¸ªå±‚çº§çš„ç¥ç»å…ƒè¾“å‡ºæ˜¯ä¸€æ ·çš„ã€‚ä¸ºäº†é¿å…ç¥ç»å…ƒå…·æœ‰ç›¸åŒçš„è¾“å‡ºï¼Œæˆ‘ä»¬ä½¿ç”¨ç‹¬ç‰¹æƒé‡ã€‚æˆ‘ä»¬è¿˜å¯ä»¥éšæœºé€‰æ‹©æƒé‡ï¼Œé¿å…æ¯ä¸ªå‘¨æœŸåçš„æŸå¤±éƒ½é™·äºå±€éƒ¨æœ€ä½ç‚¹ã€‚\n",
        "\n",
        "è·å–éšæœºæƒé‡çš„å¾ˆå¥½æ–¹æ³•æ˜¯ä»å‡åŒ€åˆ†å¸ƒé‡Œå–æ ·ã€‚\n",
        "\n",
        "\n",
        "###**å‡åŒ€åˆ†å¸ƒ**\n",
        "\n",
        "[å‡åŒ€åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Uniform_distribution_(continuous%29)ä»ä¸€ç»„æ•°å­—é‡Œé€‰æ‹©ä»»ä½•æ•°å­—çš„æ¦‚ç‡æ˜¯ä¸€æ ·çš„ã€‚æˆ‘ä»¬å°†ä»è¿ç»­åˆ†å¸ƒé‡Œé€‰æ‹©æ•°å­—ï¼Œå› æ­¤é€‰æ‹©ç›¸åŒæ•°å­—çš„æ¦‚ç‡å¾ˆä½ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ NumPy çš„ np.random.uniform å‡½æ•°ä»å‡åŒ€åˆ†å¸ƒé‡Œéšæœºé€‰æ‹©æ•°å­—ã€‚\n",
        "\n",
        "\n",
        "\n",
        "> ```\n",
        "np.random_uniform(low=0.0, high=1.0, size=None)`\n",
        "```\n",
        "ä»å‡åŒ€åˆ†å¸ƒé‡Œéšæœºé€‰æ‹©å€¼ã€‚\n",
        "\n",
        "> ç”Ÿæˆçš„å€¼ç¬¦åˆå‡åŒ€åˆ†å¸ƒï¼ŒèŒƒå›´æ˜¯[low, high)ã€‚ä¸‹é™åŒ…å«åœ¨å†…ï¼Œè€Œä¸Šé™ä¸åŒ…å«ã€‚\n",
        "\n",
        "> *   lowï¼šè¦ç”Ÿæˆçš„éšæœºå€¼çš„èŒƒå›´ä¸‹é™ã€‚é»˜è®¤ä¸º 0ã€‚\n",
        "*   highï¼šè¦ç”Ÿæˆçš„éšæœºå€¼çš„èŒƒå›´ä¸Šé™ã€‚é»˜è®¤ä¸º 1ã€‚\n",
        "*   å¤§å°ï¼šä¸€ä¸ªæ•´æ•°æˆ–æ•´æ•°å…ƒç»„ï¼ŒæŒ‡å®šè¾“å‡ºæ•°ç»„çš„å½¢çŠ¶ã€‚\n",
        "\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›´æ–¹å›¾å¯è§†åŒ–å‡åŒ€åˆ†å¸ƒã€‚æˆ‘ä»¬ä½¿ç”¨ helper.hist_dist å‡½æ•°å°† np.random_uniform(-3, 3, [1000]) ä¸­çš„å€¼æ˜ å°„åˆ°ç›´æ–¹å›¾ã€‚å®ƒä»¬å°†æ˜¯ 1000 ä¸ªéšæœºæµ®ç‚¹å€¼ï¼ŒèŒƒå›´ä» -3 åˆ° 3ï¼Œä¸å«å€¼ 3ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOJR8-BBxB_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "helpers.hist_dist('Random Uniform (low=-3, high=3)', np.random.uniform(-3, 3, [1000]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHpBYlc-xGvm",
        "colab_type": "text"
      },
      "source": [
        "ç›´æ–¹å›¾é’ˆå¯¹ 1000 ä¸ªå€¼ä½¿ç”¨äº† 500 ä¸ªåŒºé—´ã€‚å› ä¸ºè½å…¥ä»»ä½•åŒºé—´çš„æ¦‚ç‡æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤æ¯ä¸ªåŒºé—´åº”è¯¥çº¦æœ‰ 2 ä¸ªå€¼ã€‚ç›´æ–¹å›¾æ­£å¥½æ˜¯è¿™ç§æ•ˆæœã€‚æŸäº›åŒºé—´æœ‰æ›´å¤šå€¼ï¼ŒæŸäº›æœ‰æ›´å°‘çš„å€¼ï¼Œä½†æ˜¯çº¦ä¸º 2 ä¸ªã€‚\n",
        "\n",
        "\n",
        "ä½ å·²ç»äº†è§£å‡åŒ€å‡½æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨ PyTorch çš„ nn.init å°†å…¶åº”ç”¨åˆ°æ¨¡å‹çš„åˆå§‹æƒé‡ä¸Šã€‚\n",
        "\n",
        "\n",
        "###**å‡åŒ€åˆ†å¸ƒï¼ŒåŸºå‡†**\n",
        "\n",
        "æˆ‘ä»¬çœ‹çœ‹ä½¿ç”¨å‡åŒ€æƒé‡åˆå§‹åŒ–æ–¹å¼çš„ç¥ç»ç½‘ç»œè®­ç»ƒæ•ˆæœå¦‚ä½•ï¼Œå…¶ä¸­ low=0.0 å’Œ high=1.0ã€‚ä¸‹é¢æˆ‘å°†æ¼”ç¤ºå¦ä¸€ç§åˆå§‹åŒ–ç½‘ç»œæƒé‡çš„æ–¹å¼ï¼ˆé™¤äº† Net ç±»ä¸­çš„ä»£ç ä¹‹å¤–ï¼‰ã€‚è¦åœ¨å‡½æ•°å®šä¹‰éƒ¨åˆ†ä¹‹å¤–å®šä¹‰æƒé‡ï¼Œä½ å¯ä»¥ï¼š\n",
        "\n",
        "\n",
        "> 1.å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒå°†æŒ‰ç…§ç½‘ç»œå±‚çº§ç±»å‹åˆ†é…æƒé‡ï¼Œç„¶å 2.ä½¿ç”¨ model.apply(fn) å°†è¿™äº›æƒé‡åº”ç”¨åˆ°åˆå§‹åŒ–çš„æ¨¡å‹ä¸Šï¼Œå®ƒä¼šå‘æ¯ä¸ªæ¨¡å‹å±‚çº§åº”ç”¨ä¸€ä¸ªå‡½æ•°ã€‚\n",
        "\n",
        "\n",
        "è¿™æ¬¡æˆ‘ä»¬å°†ä½¿ç”¨ weight.data.uniform_ ç›´æ¥åˆå§‹åŒ–æ¨¡å‹çš„æƒé‡ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oyc9Pe7xT9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes in a module and applies the specified weight initialization\n",
        "def weights_init_uniform(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model..\n",
        "    if classname.find('Linear') != -1:\n",
        "        # apply a uniform distribution to the weights and a bias=0\n",
        "        m.weight.data.uniform_(0.0, 1.0)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez5buf18xVBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new model with these weights\n",
        "model_uniform = Net()\n",
        "model_uniform.apply(weights_init_uniform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsA_2FZVxXh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate behavior \n",
        "helpers.compare_init_weights([(model_uniform, 'Uniform Weights')], \n",
        "                             'Uniform Baseline', \n",
        "                             train_loader,\n",
        "                             valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OxYYSQdxn-v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "æŸå¤±å›¾è¡¨æ˜ç¥ç»ç½‘ç»œåœ¨å­¦ä¹ ï¼Œè€Œæƒé‡å…¨ä¸º 0 æˆ– 1 æ—¶æ²¡æœ‰åœ¨å­¦ä¹ ã€‚è¿™è¡¨ç¤ºæˆ‘ä»¬çš„åšæ³•æ˜¯æ­£ç¡®çš„ï¼\n",
        "\n",
        "###**è®¾ç½®æƒé‡çš„ä¸€èˆ¬æ³•åˆ™**\n",
        "è®¾ç½®ç¥ç»ç½‘ç»œæƒé‡çš„ä¸€èˆ¬æ³•åˆ™æ˜¯å°†å®ƒä»¬è®¾ä¸ºæ¥è¿‘ 0ï¼Œä½†æ˜¯ä¸èƒ½å¤ªå°ã€‚\n",
        "\n",
        "\n",
        "> å»ºè®®åˆå§‹æƒé‡çš„èŒƒå›´æ˜¯  [âˆ’ğ‘¦,ğ‘¦] ï¼Œå…¶ä¸­  ğ‘¦=1/ğ‘›â¯â¯âˆš \n",
        "ï¼ˆ ğ‘›  æ˜¯æŒ‡ç»™å®šç¥ç»å…ƒçš„è¾“å…¥æ•°é‡ï¼‰ã€‚\n",
        "\n",
        "\n",
        "æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ³•åˆ™æ˜¯å¦æˆç«‹ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŸºå‡†æ¨¡å‹ï¼Œå¹¶ä½¿å‡åŒ€åˆ†å¸ƒä»¥ 0 å±…ä¸­ï¼ŒèŒƒå›´åç§» 0.5ï¼Œå¾—å‡ºèŒƒå›´æ˜¯ [-0.5, 0.5)ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-QPc8N-x2Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes in a module and applies the specified weight initialization\n",
        "def weights_init_uniform_center(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model..\n",
        "    if classname.find('Linear') != -1:\n",
        "        # apply a centered, uniform distribution to the weights\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "# create a new model with these weights\n",
        "model_centered = Net()\n",
        "model_centered.apply(weights_init_uniform_center)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx5IRqRVx5Rn",
        "colab_type": "text"
      },
      "source": [
        "ç„¶ååˆ›å»ºä¸€ä¸ªåˆ†å¸ƒå’Œä½¿ç”¨ä¸€èˆ¬æ³•åˆ™åˆå§‹åŒ–æƒé‡çš„æ¨¡å‹ï¼›èŒƒå›´æ˜¯  [âˆ’ğ‘¦,ğ‘¦] ï¼Œå…¶ä¸­  ğ‘¦=1/ğ‘›â¯â¯âˆš ã€‚\n",
        "\n",
        "æœ€åæ¯”è¾ƒè¿™ä¸¤ç§æ¨¡å‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OS8yukox8RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes in a module and applies the specified weight initialization\n",
        "def weights_init_uniform_rule(m):\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model..\n",
        "    if classname.find('Linear') != -1:\n",
        "        # get the number of the inputs\n",
        "        n = m.in_features\n",
        "        y = 1.0/np.sqrt(n)\n",
        "        m.weight.data.uniform_(-y, y)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "# create a new model with these weights\n",
        "model_rule = Net()\n",
        "model_rule.apply(weights_init_uniform_rule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekYUsYK8x_VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare these two models\n",
        "model_list = [(model_centered, 'Centered Weights [-0.5, 0.5)'), \n",
        "              (model_rule, 'General Rule [-y, y)')]\n",
        "\n",
        "# evaluate behavior \n",
        "helpers.compare_init_weights(model_list, \n",
        "                             '[-0.5, 0.5) vs [-y, y)', \n",
        "                             train_loader,\n",
        "                             valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WXqqoYzzP0X",
        "colab_type": "text"
      },
      "source": [
        "æ¨¡å‹è¡Œä¸ºå¾ˆä¸é”™ï¼ä¸ä»…æŸå¤±é™ä½äº†ï¼Œè€Œä¸”éµå®ˆä¸€èˆ¬æ³•åˆ™çš„å‡åŒ€æƒé‡æŸå¤±ä¼¼ä¹ä¸‹é™å¾—å¾ˆå¿«ï¼›ä»…è¿‡äº†ä¸¤ä¸ªå‘¨æœŸï¼ŒéªŒè¯å‡†ç¡®ç‡å°±å¾ˆé«˜äº†ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆåˆé€‚çš„åˆå§‹æƒé‡éå¸¸æœ‰åŠ©äºæ¨¡å‹è®­ç»ƒï¼\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnxVFXiKzTzO",
        "colab_type": "text"
      },
      "source": [
        "ç”±äºå‡åŒ€åˆ†å¸ƒä»æŸä¸ªèŒƒå›´é‡Œé€‰æ‹©ä»»ä½•å€¼çš„æ¦‚ç‡æ˜¯ä¸€æ ·çš„ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¸€ç§åˆ†å¸ƒï¼Œè¿™ç§åˆ†å¸ƒä¸‹ï¼Œæ¥è¿‘ 0 çš„å€¼è¢«é€‰æ‹©çš„æ¦‚ç‡æ›´é«˜ï¼Œåˆä¼šæ€æ ·ï¼Ÿæˆ‘ä»¬æ¥çœ‹çœ‹æ­£æ€åˆ†å¸ƒã€‚\n",
        "\n",
        "\n",
        "###**æ­£æ€åˆ†å¸ƒ**\n",
        "ä¸å‡åŒ€åˆ†å¸ƒä¸åŒï¼Œ[æ­£æ€åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Normal_distribution)ä¸‹ï¼Œæ¥è¿‘å‡å€¼çš„æ•°å­—è¢«é€‰ä¸­çš„æ¦‚ç‡æ›´é«˜ã€‚è¦å¯è§†åŒ–æ­£æ€åˆ†å¸ƒï¼Œæˆ‘ä»¬å°† NumPy çš„ np.random.normal å‡½æ•°ä¸­çš„å€¼ç»˜åˆ¶ä¸ºç›´æ–¹å›¾ã€‚\n",
        "\n",
        "\n",
        "\n",
        ">```\n",
        "np.random.normal(loc=0.0, scale=1.0, size=None)\n",
        "```\n",
        "\n",
        "\n",
        "> ä»æ­£æ€åˆ†å¸ƒé‡Œéšæœºé€‰æ‹©å€¼ã€‚\n",
        "\n",
        "\n",
        "\n",
        "> *   locï¼šæ­£æ€åˆ†å¸ƒçš„å‡å€¼ã€‚\n",
        "*   scaleï¼šæ­£æ€åˆ†å¸ƒçš„æ ‡å‡†åå·®ã€‚\n",
        "*   shapeï¼šè¾“å‡ºæ•°ç»„çš„å½¢çŠ¶ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lGpijXy8Kur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "helpers.hist_dist('Random Normal (mean=0.0, stddev=1.0)', np.random.normal(size=[1000]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Emn3_ld8N_A",
        "colab_type": "text"
      },
      "source": [
        "æˆ‘ä»¬å°†æ­£æ€åˆ†å¸ƒä¸ä¹‹å‰éµå®ˆä¸€èˆ¬æ³•åˆ™çš„å‡åŒ€åˆ†å¸ƒè¿›è¡Œæ¯”è¾ƒã€‚\n",
        "\n",
        "\n",
        "**TODOï¼šå®šä¹‰ä¸€ä¸ªæƒé‡åˆå§‹åŒ–å‡½æ•°ï¼Œä»æ­£æ€åˆ†å¸ƒé‡Œè·å–æƒé‡**\n",
        "\n",
        "\n",
        "> æ­£æ€åˆ†å¸ƒçš„å‡å€¼åº”ä¸º 0ï¼Œæ ‡å‡†åå·®  ğ‘¦=1/ğ‘›â¯â¯âˆš\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MjJ5YW18YQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## complete this function\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "       values taken from a normal distribution.'''\n",
        "    \n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    # m.weight.data shoud be taken from a normal distribution\n",
        "    # m.bias.data should be 0\n",
        "    if classname.find('Linear') != -1:\n",
        "        # get the number of the inputs\n",
        "        n = m.in_features\n",
        "        y = 1.0/np.sqrt(n)\n",
        "        m.weight.data.normal_(0, y)\n",
        "        m.bias.data.fill_(0)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmED-Mvd8bTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## -- no need to change code below this line -- ##\n",
        "\n",
        "# create a new model with the rule-based, uniform weights\n",
        "model_uniform_rule = Net()\n",
        "model_uniform_rule.apply(weights_init_uniform_rule)\n",
        "\n",
        "# create a new model with the rule-based, NORMAL weights\n",
        "model_normal_rule = Net()\n",
        "model_normal_rule.apply(weights_init_normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0N-wzjr8d4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare the two models\n",
        "model_list = [(model_uniform_rule, 'Uniform Rule [-y, y)'), \n",
        "              (model_normal_rule, 'Normal Distribution')]\n",
        "\n",
        "# evaluate behavior \n",
        "helpers.compare_init_weights(model_list, \n",
        "                             'Uniform vs Normal', \n",
        "                             train_loader,\n",
        "                             valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luryom1L8sU_",
        "colab_type": "text"
      },
      "source": [
        "åœ¨è¿™ç§æƒ…å½¢ä¸‹ï¼Œæ­£æ€åˆ†å¸ƒçš„è¡Œä¸ºå’Œå‡åŒ€åˆ†å¸ƒçš„å¾ˆç›¸ä¼¼ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºç½‘ç»œå¾ˆå°ï¼Œå¤§å‹ç½‘ç»œå°†ä»æ¯ç§åˆ†å¸ƒé‡ŒæŠ½å–æ›´å¤šæƒé‡å€¼ï¼Œä»è€Œæ”¾å¤§ä¸¤ç§åˆå§‹åŒ–æ–¹å¼çš„å½±å“ã€‚é€šå¸¸ï¼Œæ­£æ€åˆ†å¸ƒä¼šä½¿æ¨¡å‹çš„æ•ˆæœæ›´å¥½ã€‚\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###**è‡ªåŠ¨åˆå§‹åŒ–**\n",
        "æˆ‘ä»¬æ¥çœ‹çœ‹æ²¡æœ‰æ˜ç¡®æƒé‡åˆå§‹åŒ–æ–¹å¼çš„æ¨¡å‹ä¼šæ€æ ·ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3qx8n0t81Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Instantiate a model with _no_ explicit weight initialization \n",
        "model_no_initialization = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eizpZLAi84TP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## evaluate the behavior using helpers.compare_init_weights\n",
        "\n",
        "# compare the two models\n",
        "model_list = [(model_no_initialization, 'No initialization')]\n",
        "\n",
        "# evaluate behavior \n",
        "helpers.compare_init_weights(model_list, \n",
        "                             'No initialization', \n",
        "                             train_loader,\n",
        "                             valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAhqgRRS89Jp",
        "colab_type": "text"
      },
      "source": [
        "åœ¨åšè¿™é“ç»ƒä¹ æ—¶ï¼Œè¯·æ€è€ƒä»¥ä¸‹é—®é¢˜ï¼š\n",
        "\n",
        "\n",
        "\n",
        "*   åœ¨ä¸¤ä¸ªå‘¨æœŸä¹‹åï¼Œå“ªç§åˆå§‹åŒ–ç­–ç•¥è®­ç»ƒæŸå¤±æœ€ä½ï¼Ÿå“ªç§ç­–ç•¥çš„éªŒè¯å‡†ç¡®ç‡æœ€é«˜ï¼Ÿ\n",
        "*   æµ‹è¯•æ‰€æœ‰è¿™äº›åˆå§‹æƒé‡æ–¹å¼åï¼Œä½ å†³å®šåœ¨æœ€ç»ˆåˆ†ç±»æ¨¡å‹é‡Œä½¿ç”¨å“ªç§æ–¹å¼ï¼Ÿ\n",
        "\n",
        "\n"
      ]
    }
  ]
}