{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_2_18.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingle-labake/deeplearn/blob/master/6/2/6_2_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v76pehk9FrB5",
        "colab_type": "text"
      },
      "source": [
        "##有限 MDP\n",
        "请使用[此链接](https://github.com/openai/gym/wiki/Table-of-environments)获取 OpenAI Gym 中的可用环境。\n",
        "\n",
        "![替代文字](https://s2.ax1x.com/2019/10/26/K0IE2q.png)\n",
        "环境索引为环境 ID，每个环境都有对应的观察空间、动作空间、奖励范围、tStepL、Trials 和 rThresh。\n",
        "\n",
        "###CartPole-v0\n",
        "在表格中查找对应于 CartPole-v0 环境的行。请记下相应的观察空间 (Box(4,)) 和动作空间 (Discrete(2))。\n",
        "![替代文字](https://s2.ax1x.com/2019/10/26/K0IBid.png)\n",
        "\n",
        "正如在 [OpenAI Gym 文档](https://gym.openai.com/docs/)中所描述的情况：\n",
        "\n",
        "\n",
        "\n",
        "> 每个环境都有第一类 Space 对象，描述了有效的动作和观察结果。\n",
        "> *   Discrete 空间允许存在固定范围的非负数。\n",
        "> *   Box 空间表示 n 维方框，因此有效动作或观察结果将是一个有 n 个数字的数组。\n",
        "\n",
        "\n",
        "###观察空间\n",
        "CartPole-v0 环境的观察空间有一个笔误：Box(4,)。因此，在每个时间点的观察结果（或状态）是有 4 个数字的数组。你可以在[此文档](https://github.com/openai/gym/wiki/CartPole-v0)中查看每个数字表示的含义。打开该页面后，向下滚动到观察空间的说明部分。\n",
        "![替代文字](https://s2.ax1x.com/2019/10/26/K0IReS.png)\n",
        "\n",
        "注意购物车速度和杆子顶端速度的最小值 (-Inf) 和最大值 (Inf)。\n",
        "\n",
        "因为数组中的条目对应的每个索引可以是任何实数，所以状态空间S+是无限的！\n",
        "\n",
        "###动作空间\n",
        "CartPole-v0 环境的动作空间类型为 Discrete(2)。因此，在任何时间点，智能体只能采取两个动作。你可以在[此文档](https://github.com/openai/gym/wiki/CartPole-v0)（注意，和查找观察空间使用的文档一样！）中查看每个数字表示的含义。打开该页面后，向下滚动到动作空间的说明部分。\n",
        "\n",
        "![替代文字](https://s2.ax1x.com/2019/10/26/K0IHyV.png)\n",
        "在这种情况下，动作空间A 是一组有限的集合，仅包含两个元素。\n",
        "\n",
        "###有限 MDP\n",
        "记得在上个部分，我们提到：在有限的 MDP 中，状态空间S（或在阶段性任务中为S \n",
        "+）和动作空间A 必须都是有限的。\n",
        " \n",
        "\n",
        "因此，虽然 CartPole-v0 环境的确指定了 MDP，它没有指定有限的 MDP。在这门课程中，我们将重点讲解有限 MDP 的解决方法。\n",
        "\n",
        "\n",
        "你在这门课程中将解决的环境为：\n",
        "\n",
        "\n",
        "*   [FrozenLake-v0](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py)\n",
        "*   [Blackjack-v0](https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py)\n",
        "*   [CliffWalking-v0](https://github.com/openai/gym/blob/master/gym/envs/toy_text/cliffwalking.py)（注意：此环境可能没有列在环境表格中）\n",
        "*   [Taxi-v2](https://github.com/openai/gym/blob/master/gym/envs/toy_text/taxi.py)\n",
        "\n",
        "\n",
        "\n",
        "如果你愿意的话，可以现在花时间详细了解这些环境。检查确保每个环境都指定有限的 MDP。"
      ]
    }
  ]
}