{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_1_27.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingle-labake/deeplearn/blob/master/2/1/2_1_27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swZ58Wxq2Tv3",
        "colab_type": "text"
      },
      "source": [
        "##梯度下降\n",
        "\n",
        "###实现梯度下降算法\n",
        "在该 Lab 中，我们将实现梯度下降算法的基本函数，以便在小数据集中查找数据边界。 首先，我们将从一些函数开始，帮助我们绘制和可视化数据。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cbLQOpM2P2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Some helper functions for plotting and drawing lines\n",
        "\n",
        "def plot_points(X, y):\n",
        "    admitted = X[np.argwhere(y==1)]\n",
        "    rejected = X[np.argwhere(y==0)]\n",
        "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'blue', edgecolor = 'k')\n",
        "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'red', edgecolor = 'k')\n",
        "\n",
        "def display(m, b, color='g--'):\n",
        "    plt.xlim(-0.05,1.05)\n",
        "    plt.ylim(-0.05,1.05)\n",
        "    x = np.arange(-10, 10, 0.1)\n",
        "    plt.plot(x, m*x+b, color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8ILxJq-2jmI",
        "colab_type": "text"
      },
      "source": [
        "###读取与绘制数据¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IG1wUYi2pcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\n",
        "X = np.array(data[[0,1]])\n",
        "y = np.array(data[2])\n",
        "plot_points(X,y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0BMmLXh2vMZ",
        "colab_type": "text"
      },
      "source": [
        "###待办： 实现基本函数\n",
        "现在轮到你练习了。 如之前所述，实现以下基本函数。\n",
        "\n",
        "![替代文字](https://s2.ax1x.com/2019/10/26/KDEout.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgjGi-Ou3AsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement the following functions\n",
        "\n",
        "# Activation (sigmoid) function\n",
        "# Activation (sigmoid) function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def output_formula(features, weights, bias):\n",
        "    return sigmoid(np.dot(features, weights) + bias)\n",
        "\n",
        "def error_formula(y, output):\n",
        "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
        "\n",
        "def update_weights(x, y, weights, bias, learnrate):\n",
        "    output = output_formula(x, weights, bias)\n",
        "    d_error = (y - output)\n",
        "    weights += learnrate * d_error * x\n",
        "    bias += learnrate * d_error\n",
        "    return weights, bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4bGbF-S3DTy",
        "colab_type": "text"
      },
      "source": [
        "###训练函数\n",
        "该函数将帮助我们通过所有数据来迭代梯度下降算法，用于多个 epoch。 它还将绘制数据，以及在我们运行算法时绘制出一些边界线。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoE1ScJE3G8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(44)\n",
        "\n",
        "epochs = 100\n",
        "learnrate = 0.01\n",
        "\n",
        "def train(features, targets, epochs, learnrate, graph_lines=False):\n",
        "    \n",
        "    errors = []\n",
        "    n_records, n_features = features.shape\n",
        "    last_loss = None\n",
        "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
        "    bias = 0\n",
        "    for e in range(epochs):\n",
        "        del_w = np.zeros(weights.shape)\n",
        "        for x, y in zip(features, targets):\n",
        "            output = output_formula(x, weights, bias)\n",
        "            error = error_formula(y, output)\n",
        "            weights, bias = update_weights(x, y, weights, bias, learnrate)\n",
        "        \n",
        "        # Printing out the log-loss error on the training set\n",
        "        out = output_formula(features, weights, bias)\n",
        "        loss = np.mean(error_formula(targets, out))\n",
        "        errors.append(loss)\n",
        "        if e % (epochs / 10) == 0:\n",
        "            print(\"\\n========== Epoch\", e,\"==========\")\n",
        "            if last_loss and last_loss < loss:\n",
        "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "            else:\n",
        "                print(\"Train loss: \", loss)\n",
        "            last_loss = loss\n",
        "            predictions = out > 0.5\n",
        "            accuracy = np.mean(predictions == targets)\n",
        "            print(\"Accuracy: \", accuracy)\n",
        "        if graph_lines and e % (epochs / 100) == 0:\n",
        "            display(-weights[0]/weights[1], -bias/weights[1])\n",
        "            \n",
        "\n",
        "    # Plotting the solution boundary\n",
        "    plt.title(\"Solution boundary\")\n",
        "    display(-weights[0]/weights[1], -bias/weights[1], 'black')\n",
        "\n",
        "    # Plotting the data\n",
        "    plot_points(features, targets)\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting the error\n",
        "    plt.title(\"Error Plot\")\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.plot(errors)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7q1AfWv3J4C",
        "colab_type": "text"
      },
      "source": [
        "###是时候来训练算法啦！\n",
        "当我们运行该函数时，我们将获得以下内容：\n",
        "\n",
        "\n",
        "\n",
        "*   目前的训练损失与准确性的 10 次更新\n",
        "*   获取的数据图和一些边界线的图。 最后一个是黑色的。请注意，随着我们遍历更多的 epoch ，线会越来越接近最佳状态。\n",
        "*   误差函数的图。 请留意，随着我们遍历更多的 epoch，它会如何降低。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Wd1Tll3XnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(X, y, epochs, learnrate, True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}