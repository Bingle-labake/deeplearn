{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_1_17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingle-labake/deeplearn/blob/master/5/1/5_1_17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqNjk4VM5g9C",
        "colab_type": "text"
      },
      "source": [
        "##改进你的 GAN\n",
        "我向你展示的 GAN，在生成器和辨别器中只使用了一个隐藏层。这个 GAN 的结果已经非常不错了，但仍然有很多噪声图像，以及有些图像看起来不太像数字。但是，要让生成器生成的图像与 MNIST 数据集几乎一样，是完全可能的。\n",
        "\n",
        "![替代文字](https://s2.ax1x.com/2019/10/26/KBKPwq.png)\n",
        "经训练的 GAN 生成的 MNIST 图像 (https://arxiv.org/pdf/1606.03498.pdf)\n",
        "\n",
        "这来自一篇题为 [Improved Techniques for Training GANs](https://arxiv.org/pdf/1606.03498.pdf) 的文章。那么，它们如何生成如此美观的图像呢？\n",
        "\n",
        "与大多数神经网络一样，使用的层越多，网络的性能就越好。所以你可以尝试两三层，而不只是一层。尝试使用有更多单元的更大的层，看看它对你的结果有何影响。\n",
        "\n",
        "\n",
        "###批次归一化\n",
        "\n",
        "提醒一下，在三层情况下你可能无法使它很好地工作。网络会变得对权重的初始值非常敏感，导致无法训练。我们可以使用 [批次归一化（Batch Normalization）](https://arxiv.org/abs/1502.03167) 来解决这个问题。原理很简单。就像我们对网络输入的做法一样，我们可以对每个层的输入进行归一化。也就是说，缩放层输入，使它具有零均值和标准差 1。经发现，批次归一化对于构建深度 GAN 非常有必要。\n",
        "\n",
        "我们将在下一周的课程中讲解批次归一化，以及对生成器和辨别器使用卷积网络。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzIKljDh5ebx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}