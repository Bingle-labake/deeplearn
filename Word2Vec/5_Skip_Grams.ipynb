{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Skip_Grams.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bingle-labake/deeplearn/blob/master/Word2Vec/5_Skip_Grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfP_CTAiWG39",
        "colab_type": "text"
      },
      "source": [
        "##Skip-gram Word2Vec\n",
        "åœ¨æ­¤ notebook ä¸­ï¼Œæˆ‘å°†è®²è§£å¦‚ä½•åœ¨ PyTorch ä¸­ä½¿ç”¨ skip-gram ç»“æ„å®ç° Word2Vec ç®—æ³•ã€‚æˆ‘ä»¬å°†å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ç”¨åˆ°çš„è¯åµŒå…¥æ¦‚å¿µã€‚è¯åµŒå…¥å¯¹äºæœºå™¨ç¿»è¯‘æ¥è¯´å¾ˆæœ‰ç”¨ã€‚\n",
        "\n",
        "###æ‰©å±•é˜…è¯»\n",
        "æˆ‘åœ¨æ„å»ºæ­¤ notebook æ—¶å‚è€ƒäº†ä»¥ä¸‹èµ„æ–™ã€‚å»ºè®®æå‰é˜…è¯»æˆ–åœ¨åšç»ƒä¹ çš„è¿‡ç¨‹ä¸­å‚è€ƒè¿™äº›èµ„æ–™ã€‚\n",
        "\n",
        "\n",
        "*   Word2Vec çš„[æ¦‚å¿µä»‹ç»](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)ï¼Œä½œè€…ï¼šChris McCormick\n",
        "*   Mikolov ç­‰äººçš„[ç¬¬ä¸€ç¯‡ Word2Vec è®ºæ–‡](https://arxiv.org/pdf/1301.3781.pdf)ã€‚\n",
        "*   [ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè®ºæ–‡](hhttp://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)ï¼ˆå¯¹ Word2Vec è¿›è¡Œäº†æ”¹è¿›ï¼‰ï¼Œä½œè€…ä¹Ÿæ˜¯ Mikolov ç­‰äººã€‚\n",
        "\n",
        "###è¯åµŒå…¥\n",
        "åœ¨å¤„ç†æ–‡æœ¬ä¸­çš„å­—è¯æ—¶ï¼Œæˆ‘ä»¬éœ€è¦åˆ†ææ•°åƒä¸ªå­—è¯ç±»åˆ«ï¼›è¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªå­—è¯å¯¹åº”ä¸€ä¸ªç±»åˆ«ã€‚å¯¹è¿™äº›å­—è¯è¿›è¡Œç‹¬çƒ­ç¼–ç æ•ˆç‡å¾ˆä½ï¼Œå› ä¸ºç‹¬çƒ­å‘é‡ä¸­çš„å¤§å¤šæ•°å€¼å°†ä¸º 0ã€‚å¦‚æœå¯¹ç‹¬çƒ­è¾“å…¥å‘é‡ä¸ç¬¬ä¸€ä¸ªéšè—å±‚è¿›è¡ŒçŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œç»“æœå°†ç”Ÿæˆä¸€ä¸ªæœ‰å¤šä¸ªå€¼ä¸º 0 çš„éšè—è¾“å‡ºå‘é‡ã€‚\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSc4v.png)\n",
        "\n",
        "ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜å¹¶æé«˜ç½‘ç»œçš„æ•ˆç‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åµŒå…¥åŠŸèƒ½ã€‚åµŒå…¥å…¶å®å°±æ˜¯å…¨è¿æ¥å±‚ï¼Œå’Œä½ ä¹‹å‰çœ‹è¿‡çš„å±‚çº§ä¸€æ ·ã€‚æˆ‘ä»¬å°†æ­¤å±‚çº§ç§°ä¸ºåµŒå…¥å±‚ï¼Œå°†æƒé‡ç§°ä¸ºåµŒå…¥æƒé‡ã€‚æˆ‘ä»¬å°†è·³è¿‡ä¸åµŒå…¥å±‚çš„ä¹˜æ³•è¿ç®—æ­¥éª¤ï¼Œç›´æ¥ä»æƒé‡çŸ©é˜µé‡Œè·å–éšè—å±‚çš„å€¼ã€‚è¿™æ˜¯å› ä¸ºç‹¬çƒ­å‘é‡ä¸çŸ©é˜µç›¸ä¹˜åï¼Œç»“æœæ˜¯â€œå¼€å¯â€è¾“å…¥å•å…ƒçš„ç´¢å¼•å¯¹åº”çš„çŸ©é˜µè¡Œã€‚\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSCJD.png)\n",
        "\n",
        "æˆ‘ä»¬å°†ä½¿ç”¨æƒé‡çŸ©é˜µä½œä¸ºæŸ¥è¯¢è¡¨ï¼Œè€Œä¸æ˜¯æ‰§è¡ŒçŸ©é˜µä¹˜æ³•è¿ç®—ã€‚æˆ‘ä»¬ç”¨æ•´æ•°è¡¨ç¤ºå­—è¯ï¼Œä¾‹å¦‚ç”¨ 958 è¡¨ç¤ºâ€œheartâ€ï¼Œç”¨ 18094 è¡¨ç¤ºâ€œmindâ€ã€‚è¦è·å–â€œheartâ€çš„éšè—å±‚å€¼ï¼Œç›´æ¥ä»åµŒå…¥çŸ©é˜µé‡Œè·å–ç¬¬ 958 è¡Œçš„å€¼ã€‚è¿™ä¸ªæµç¨‹ç§°ä¸ºåµŒå…¥æŸ¥è¯¢ï¼Œéšè—å•å…ƒçš„æ•°é‡ç§°ä¸ºåµŒå…¥ç»´åº¦ã€‚\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSlFu.png)\n",
        "\n",
        "å…¶å®æ²¡ä»€ä¹ˆç¥å¥‡ä¹‹å¤„ã€‚åµŒå…¥æŸ¥è¯¢è¡¨åªæ˜¯æƒé‡çŸ©é˜µã€‚åµŒå…¥å±‚åªæ˜¯éšè—å±‚ã€‚æŸ¥è¯¢æ˜¯çŸ©é˜µä¹˜æ³•çš„ä¾¿æ·è¿ç®—ã€‚æˆ‘ä»¬åƒè®­ç»ƒä»»ä½•å…¶ä»–æƒé‡çŸ©é˜µä¸€æ ·è®­ç»ƒæŸ¥è¯¢è¡¨ã€‚\n",
        "\n",
        "å½“ç„¶ï¼ŒåµŒå…¥å¹¶ä¸æ˜¯ä»…é€‚ç”¨äºå­—è¯ã€‚å®ƒä»¬å¯ä»¥ç”¨äºä»»ä½•ç±»åˆ«æ•°é‡åºå¤§çš„æ¨¡å‹ã€‚æœ‰ä¸€ç§ç‰¹æ®Šçš„æ¨¡å‹å«åš Word2Vecï¼Œå®ƒä½¿ç”¨åµŒå…¥å±‚æŸ¥æ‰¾åŒ…å«ç‰¹å®šè¯­ä¹‰ä¿¡æ¯çš„å‘é‡è¡¨ç¤ºæ³•ã€‚\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###Word2Vec\n",
        "Word2Vec ç®—æ³•é€šè¿‡æŸ¥æ‰¾è¡¨ç¤ºå­—è¯çš„å‘é‡ï¼Œå¾—å‡ºæ›´é«˜æ•ˆçš„è¡¨ç¤ºæ³•ã€‚è¿™äº›å‘é‡ä¹ŸåŒ…å«å…³äºå­—è¯çš„è¯­ä¹‰ä¿¡æ¯ã€‚\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSeAa.png)\n",
        "\n",
        "å‡ºç°åœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡é‡Œçš„å­—è¯å°†å…·æœ‰ç›¸äº’é è¿‘çš„å‘é‡ï¼Œä¾‹å¦‚â€œcoffeeâ€ã€â€œteaâ€å’Œâ€œwaterâ€ã€‚ä¸åŒå­—è¯çš„å‘é‡ç›¸äº’ä¹‹é—´ç¦»å¾—æ›´è¿œï¼Œåœ¨å‘é‡ç©ºé—´é‡Œçš„è·ç¦»å¯ä»¥è¡¨ç¤ºå­—è¯ä¹‹é—´çš„å…³ç³»ã€‚\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSnwd.png)\n",
        "\n",
        "Word2Vec æœ‰ä¸¤ç§å®ç°ç»“æ„ï¼š\n",
        "\n",
        "\n",
        "*   CBOWï¼ˆè¿ç»­è¯è¢‹æ¨¡å‹ï¼‰ï¼Œä»¥åŠ\n",
        "*   Skip-gram\n",
        "\n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSIL1.png)\n",
        "\n",
        "åœ¨æ­¤ notebook ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ skip-gram ç»“æ„ï¼Œå› ä¸ºå®ƒçš„æ•ˆæœæ¯” CBOW å¥½ã€‚å¯¹äº skip-gram ç»“æ„ï¼Œæˆ‘ä»¬å°†ä¼ å…¥ä¸€ä¸ªå­—è¯ï¼Œå¹¶å°è¯•é¢„æµ‹å®ƒåœ¨æ–‡æœ¬é‡Œçš„ä¸Šä¸‹æ–‡å­—è¯ã€‚è¿™æ ·æˆ‘ä»¬ä¾¿èƒ½è®­ç»ƒç½‘ç»œå­¦ä¹ å‡ºç°åœ¨ç›¸ä¼¼ä¸Šä¸‹æ–‡é‡Œçš„å­—è¯çš„è¡¨ç¤ºæ³•ã€‚\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###åŠ è½½æ•°æ®\n",
        "ä¸‹é¢è¯·åŠ è½½æ•°æ®å¹¶å°†å…¶æ”¾å…¥ data ç›®å½•ä¸­\n",
        "\n",
        "\n",
        "1.   åŠ è½½ [text8 æ•°æ®é›†](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/October/5bbe6499_text8/text8.zip)ï¼›å®ƒæ˜¯ä¸€ä¸ªç»è¿‡æ¸…ç†çš„ç»´åŸºç™¾ç§‘æ–‡ç« æ–‡æœ¬æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶ç”± Matt Mahoney æä¾›ã€‚ 2.å°†æ•°æ®æ”¾å…¥ä¸»ç›®å½•ä¸­çš„ data æ–‡ä»¶å¤¹ä¸‹ã€‚ 3.ç„¶åè§£å‹ ZIP æ–‡ä»¶å¹¶åˆ é™¤ ZIP æ–‡ä»¶ä»¥é‡Šæ”¾å­˜å‚¨ç©ºé—´ã€‚\n",
        "\n",
        "\n",
        "\n",
        "å®Œæˆè¿™äº›æ­¥éª¤ä¹‹åï¼Œæ•°æ®ç›®å½•ä¸­åº”è¯¥åªæœ‰ data/text8 è¿™ä¸ªæ–‡ä»¶ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwfNoiwAbG7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in the extracted text file      \n",
        "with open('data/text8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# print out the first 100 characters\n",
        "print(text[:100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r52TaqkbMjz",
        "colab_type": "text"
      },
      "source": [
        "###é¢„å¤„ç†\n",
        "æˆ‘å°†é¢„å¤„ç†æ–‡æœ¬ï¼Œä½¿è®­ç»ƒæµç¨‹æ›´æ–¹ä¾¿ã€‚æ‰“å¼€ utils.py æ–‡ä»¶ã€‚å…¶ä¸­çš„ preprocess å‡½æ•°å°†æ‰§è¡Œä»¥ä¸‹å‡ ä¸ªæ“ä½œï¼š\n",
        "\n",
        "\n",
        "*   å°†æ‰€æœ‰æ ‡ç‚¹è½¬æ¢ä¸ºæ ‡è®°ï¼Œå› æ­¤â€œ.â€å˜æˆ <PERIOD>ã€‚è™½ç„¶æ­¤æ•°æ®é›†æ²¡æœ‰ä»»ä½•æ ‡ç‚¹ï¼Œä½†æ˜¯è¿™ä¸€æ­¥å¯¹å…¶ä»– NLP é—®é¢˜æ¥è¯´å¾ˆæœ‰ç”¨ã€‚\n",
        "*   åˆ é™¤åœ¨æ•°æ®é›†ä¸­å‡ºç°æ¬¡æ•°ä¸è¶…è¿‡ 5 æ¬¡çš„å­—è¯ã€‚è¿™æ ·èƒ½å¤Ÿæ˜¾è‘—å‡å°‘æ•°æ®å™ªç‚¹å¸¦æ¥çš„é—®é¢˜ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¹å–„å‘é‡è¡¨ç¤ºæ³•çš„è´¨é‡ã€‚\n",
        "*   è¿”å›ç”±æ–‡æœ¬ä¸­çš„ä¸€äº›å­—è¯æ„æˆçš„åˆ—è¡¨ã€‚\n",
        "\n",
        "\n",
        "ç”±äºæ–‡æœ¬æ–‡ä»¶å¾ˆåºå¤§ï¼Œæ‰€ä»¥è¿è¡Œæ—¶é—´å¯èƒ½è¾ƒé•¿ã€‚å¦‚æœä½ æƒ³è‡ªå·±ç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œå°±å°½ç®¡å°è¯•å§ï¼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIFpIDnMV3WQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils\n",
        "\n",
        "# get list of words\n",
        "words = utils.preprocess(text)\n",
        "print(words[:30])\n",
        "\n",
        "# print some stats about this word data\n",
        "print(\"Total words in text: {}\".format(len(words)))\n",
        "print(\"Unique words: {}\".format(len(set(words)))) # `set` removes any duplicate words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBiIrmahblaE",
        "colab_type": "text"
      },
      "source": [
        "###å­—å…¸\n",
        "ä¸‹é¢æˆ‘å°†åˆ›å»ºä¸¤ä¸ªå­—å…¸ï¼Œä¸€ä¸ªå°†å­—è¯è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦ä¸€ä¸ªå°†æ•´æ•°è½¬æ¢ä¸ºå­—è¯ã€‚åŒæ ·åœ¨ utils.py æ–‡ä»¶é‡Œä½¿ç”¨ä¸€ä¸ªå‡½æ•°å®Œæˆè¿™ä¸ªæ­¥éª¤ã€‚create_lookup_tables çš„è¾“å…¥å‚æ•°æ˜¯ä¸€ä¸ªæ–‡æœ¬å­—è¯åˆ—è¡¨ï¼Œå¹¶è¿”å›ä¸¤ä¸ªå­—å…¸ã€‚\n",
        "\n",
        "\n",
        "1.   æŒ‰ç…§é¢‘ç‡é™åºåˆ†é…æ•´æ•°ï¼Œæœ€å¸¸è§çš„å­—è¯â€œtheâ€å¯¹åº”çš„æ•´æ•°æ˜¯ 0ï¼Œç¬¬äºŒå¸¸è§çš„å­—è¯æ˜¯ 1ï¼Œä»¥æ­¤ç±»æ¨ã€‚\n",
        "\n",
        "\n",
        "åˆ›å»ºå¥½å­—å…¸åï¼Œå°†å­—è¯è½¬æ¢ä¸ºæ•´æ•°å¹¶å­˜å‚¨åœ¨ int_words åˆ—è¡¨ä¸­ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC0pePigbyDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_int, int_to_vocab = utils.create_lookup_tables(words)\n",
        "int_words = [vocab_to_int[word] for word in words]\n",
        "\n",
        "print(int_words[:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNVR9FTqb4Cm",
        "colab_type": "text"
      },
      "source": [
        "###äºŒæ¬¡é‡‡æ ·\n",
        "â€œtheâ€ã€â€œofâ€å’Œâ€œforâ€ç­‰ç»å¸¸å‡ºç°çš„å­—è¯å¹¶ä¸èƒ½ä¸ºé™„è¿‘çš„å­—è¯æä¾›å¾ˆå¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å¦‚æœä¸¢å¼ƒæŸäº›å¸¸è§å­—è¯ï¼Œåˆ™èƒ½æ¶ˆé™¤æ•°æ®ä¸­çš„ä¸€äº›å™ªç‚¹ï¼Œå¹¶æé«˜è®­ç»ƒé€Ÿåº¦å’Œæ”¹å–„è¡¨ç¤ºæ³•çš„è´¨é‡ã€‚Mikolov å°†è¿™ä¸ªæµç¨‹ç§°ä¸ºäºŒæ¬¡é‡‡æ ·ã€‚å¯¹äºè®­ç»ƒé›†ä¸­çš„æ¯ä¸ªå­—è¯  ğ‘¤ğ‘– ï¼Œæˆ‘ä»¬å°†æ ¹æ®æŸä¸ªæ¦‚ç‡ä¸¢å¼ƒè¯¥å­—è¯ï¼Œå…¬å¼ä¸ºï¼š\n",
        "\n",
        "ğ‘ƒ(ğ‘¤ğ‘–)=1âˆ’ğ‘¡ğ‘“(ğ‘¤ğ‘–)â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯âˆš\n",
        " \n",
        "å…¶ä¸­  ğ‘¡  æ˜¯é˜ˆå€¼å‚æ•°ï¼Œ ğ‘“(ğ‘¤ğ‘–)  æ˜¯å­—è¯  ğ‘¤ğ‘–  åœ¨æ€»æ•°æ®é›†ä¸­çš„é¢‘ç‡ã€‚\n",
        "\n",
        "ğ‘ƒ(0)=1âˆ’1âˆ—10âˆ’51âˆ—106/16âˆ—106â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯â¯âˆš=0.98735\n",
        " \n",
        "ä¸‹é¢å¸ƒç½®ä¸€é“ç»ƒä¹ é¢˜ä½ å¯ä»¥çœ‹çœ‹æˆ‘çš„å®ç°æ–¹å¼ã€‚\n",
        "\n",
        "\n",
        "> ***ç»ƒä¹ ï¼šå¯¹ int_words ä¸­çš„å­—è¯è¿›è¡ŒäºŒæ¬¡é‡‡æ ·ã€‚å³è®¿é—® int_words å¹¶æ ¹æ®ä¸Šé¢æ‰€ç¤ºçš„æ¦‚ç‡  ğ‘ƒ(ğ‘¤ğ‘–)  ä¸¢å¼ƒæ¯ä¸ªå­—è¯ã€‚æ³¨æ„ï¼Œ ğ‘ƒ(ğ‘¤ğ‘–)  è¡¨ç¤ºä¸¢å¼ƒæŸä¸ªå­—è¯çš„æ¦‚ç‡ã€‚å°†äºŒæ¬¡é‡‡æ ·çš„æ•°æ®èµ‹å€¼ç»™ train_wordsã€‚***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_JvY2jTcf-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "threshold = 1e-5\n",
        "word_counts = Counter(int_words)\n",
        "print(list(word_counts.items())[0])  # dictionary of int_words, how many times they appear\n",
        "\n",
        "# discard some frequent words, according to the subsampling equation\n",
        "# create a new list of words for training\n",
        "total_items_count = len(int_words)\n",
        "word_freqs        = {word:count/total_items_count for word,count in word_counts.items()}\n",
        "p_words           = {word:1-np.sqrt(threshold/word_freqs[word]) for word in word_counts}\n",
        "train_words       = [word for word in int_words if random.random() < (1-p_words[word])]\n",
        "print(train_words[:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iycIbyXxcktI",
        "colab_type": "text"
      },
      "source": [
        "###åˆ›å»ºæ‰¹æ¬¡\n",
        "å‡†å¤‡å¥½æ•°æ®åï¼Œæˆ‘ä»¬éœ€è¦æ‰¹å¤„ç†æ•°æ®ï¼Œç„¶åæ‰èƒ½ä¼ å…¥ç½‘ç»œä¸­ã€‚åœ¨ä½¿ç”¨ skip-gram ç»“æ„æ—¶ï¼Œå¯¹äºæ–‡æœ¬ä¸­çš„æ¯ä¸ªå­—è¯ï¼Œæˆ‘ä»¬éƒ½éœ€è¦å®šä¹‰ä¸Šä¸‹æ–‡çª—å£ï¼ˆå¤§å°ä¸º  ğ¶ ï¼‰ï¼Œç„¶åè·å–çª—å£ä¸­çš„æ‰€æœ‰å­—è¯ã€‚\n",
        "\n",
        "æ‘˜è‡ª Mikolov et al.ï¼š\n",
        "\n",
        "\"Since the more distant words are usually less related to the current word than those close to it, we give less weight to the distant words by sampling less from those words in our training examples...If we choose  ğ¶=5 , for each training word we will select randomly a number  ğ‘…  in range  [1:ğ¶] , and then use  ğ‘… words from history and  ğ‘…  words from the future of the current word as correct labels.\"\n",
        "\n",
        "\n",
        "\n",
        "> ***ç»ƒä¹ ï¼šè¯·å®ç°å‡½æ•° get_targetï¼Œè¾“å…¥å‚æ•°ä¸ºå­—è¯åˆ—è¡¨ã€ç´¢å¼•å’Œçª—å£å¤§å°ï¼Œç„¶åè¿”å›è¯¥ç´¢å¼•æ‰€åœ¨çª—å£ä¸­çš„å­—è¯åˆ—è¡¨ã€‚è¯·ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ç®—æ³•ï¼Œå³ä»çª—å£é‡Œé€‰æ‹©éšæœºæ•°é‡çš„å­—è¯ã€‚***\n",
        "\n",
        "\n",
        "\n",
        "å‡è®¾æœ‰ä¸€æ®µè¾“å…¥æ–‡æœ¬ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯¹ idx=2 å¤„çš„æ ‡è®° 741 æ„Ÿå…´è¶£ï¼š\n",
        "\n",
        "[5233, 58, 741, 10571, 27349, 0, 15067, 58112, 3580, 58, 10712]\n",
        "\n",
        "å¦‚æœ R=2ï¼Œget_target åº”è¯¥è¿”å›æœ‰ 4 ä¸ªå€¼çš„åˆ—è¡¨ï¼š\n",
        "\n",
        "[5233, 58, 10571, 27349]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHnZd4aCc67q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_target(words, idx, window_size=5):\n",
        "    ''' Get a list of words in a window around an index. '''\n",
        "    \n",
        "    # implement this function\n",
        "    c = len(words)\n",
        "    R = np.random.randint(1, window_size+1)\n",
        "    \n",
        "    s_idx =  (idx - R) if (idx - R) > 0 else 0\n",
        "    e_idx =  (idx + R) if (idx + R) <= c else c\n",
        "   \n",
        "    return words[s_idx:idx] + words[idx+1:e_idx+1]\n",
        "\n",
        "# test your code!\n",
        "\n",
        "# run this cell multiple times to check for random window selection\n",
        "int_text = [i for i in range(10)]\n",
        "print('Input: ', int_text)\n",
        "idx=5 # word index of interest\n",
        "\n",
        "target = get_target(int_text, idx=idx, window_size=5)\n",
        "print('Target: ', target)  # you should get some indices around the idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhwrSzK5dEeS",
        "colab_type": "text"
      },
      "source": [
        "###ç”Ÿæˆæ‰¹æ¬¡æ•°æ®\n",
        "ä¸‹é¢çš„ç”Ÿæˆå™¨å‡½æ•°å°†ä½¿ç”¨ä¸Šè¿° get_target å‡½æ•°è¿”å›å¤šæ‰¹è¾“å…¥å’Œç›®æ ‡æ•°æ®ã€‚å®ƒä¼šä»å­—è¯åˆ—è¡¨ä¸­è·å– batch_size ä¸ªå­—è¯ã€‚å¯¹äºæ¯æ‰¹æ•°æ®ï¼Œå®ƒéƒ½ä¼šè·å–çª—å£ä¸­çš„ç›®æ ‡ä¸Šä¸‹æ–‡å­—è¯ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YycJTcJ1dGSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(words, batch_size, window_size=5):\n",
        "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
        "    \n",
        "    n_batches = len(words)//batch_size\n",
        "    \n",
        "    # only full batches\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    for idx in range(0, len(words), batch_size):\n",
        "        x, y = [], []\n",
        "        batch = words[idx:idx+batch_size]\n",
        "        for ii in range(len(batch)):\n",
        "            batch_x = batch[ii]\n",
        "            batch_y = get_target(batch, ii, window_size)\n",
        "\n",
        "            y.extend(batch_y)\n",
        "            x.extend([batch_x]*len(batch_y))\n",
        "        yield x, y\n",
        "    \n",
        "    \n",
        "int_text = [i for i in range(20)]\n",
        "x,y = next(get_batches(int_text, batch_size=4, window_size=5))\n",
        "\n",
        "print('x\\n', x)\n",
        "print('y\\n', y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY00ORjBdQ9z",
        "colab_type": "text"
      },
      "source": [
        "###ç¤ºæ„å›¾\n",
        "ä¸‹é¢æ˜¯ç½‘ç»œçš„å¤§è‡´ç¤ºæ„å›¾ã€‚ \n",
        "\n",
        "![æ›¿ä»£æ–‡å­—](https://t1.picb.cc/uploads/2019/06/13/glSmji.png)\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "1.   è¾“å…¥å­—è¯ä»¥å¤šæ‰¹è¾“å…¥å­—è¯æ ‡è®°çš„å½¢å¼ä¼ å…¥ç½‘ç»œä¸­ã€‚\n",
        "2.   è¿™äº›è¾“å…¥å­—è¯å°†è¿›å…¥ä¸€ä¸ªç”±çº¿æ€§å•å…ƒç»„æˆçš„éšè—å±‚ï¼ˆå³åµŒå…¥å±‚ï¼‰ã€‚\n",
        "3.   æœ€åæ˜¯ä¸€ä¸ª softmax è¾“å‡ºå±‚ã€‚\n",
        "4.   æˆ‘ä»¬å°†åœ¨ softmax å±‚çº§é€šè¿‡æŠ½æ ·é¢„æµ‹ä¸Šä¸‹æ–‡å­—è¯ã€‚\n",
        "\n",
        "\n",
        "åŸç†æ˜¯è®­ç»ƒåµŒå…¥å±‚æƒé‡çŸ©é˜µï¼Œå¹¶æŸ¥æ‰¾å­—è¯çš„æœ‰æ•ˆè¡¨ç¤ºæ³•ã€‚æˆ‘ä»¬å¯ä»¥åˆ æ‰ softmax å±‚çº§ï¼Œå› ä¸ºæˆ‘ä»¬å¹¶ä¸éœ€è¦ç”¨æ­¤ç½‘ç»œåšå‡ºé¢„æµ‹ã€‚æˆ‘ä»¬åªæƒ³è·å¾—åµŒå…¥çŸ©é˜µï¼Œä»è€Œåœ¨æ ¹æ®è¯¥æ•°æ®é›†æ„å»ºçš„å…¶ä»–ç½‘ç»œä¸­ä½¿ç”¨è¿™äº›åµŒå…¥ã€‚\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###éªŒè¯\n",
        "ä¸‹é¢åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå®ƒä¼šåœ¨æ¨¡å‹å­¦ä¹ è¿‡ç¨‹ä¸­è§‚å¯Ÿæ¨¡å‹ã€‚æˆ‘ä»¬å°†é€‰æ‹©ä¸€äº›å¸¸è§å­—è¯å’Œä¸å¸¸è§å­—è¯ã€‚ç„¶åä½¿ç”¨ç›¸ä¼¼æ€§ä½™å¼¦è¾“å‡ºæœ€é è¿‘çš„å­—è¯ã€‚\n",
        "\n",
        "similarity=cos(ğœƒ)=ğ‘âƒ— â‹…ğ‘âƒ— |ğ‘âƒ— ||ğ‘âƒ— |\n",
        " \n",
        "æˆ‘ä»¬ä½¿ç”¨åµŒå…¥è¡¨å°†éªŒè¯å­—è¯è¡¨ç¤ºä¸ºå‘é‡  ğ‘âƒ—  ï¼Œç„¶åè®¡ç®—ä¸åµŒå…¥è¡¨ä¸­æ¯ä¸ªå­—è¯å‘é‡  ğ‘âƒ—   ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚ç®—å‡ºç›¸ä¼¼ç¨‹åº¦åï¼Œæˆ‘ä»¬å°†è¾“å‡ºéªŒè¯å­—è¯ä»¥åŠåµŒå…¥è¡¨ä¸­ä¸è¿™äº›å­—è¯è¯­ä¹‰ç›¸ä¼¼çš„å­—è¯ã€‚è¿™æ ·ä¾¿äºæˆ‘ä»¬æ£€æŸ¥åµŒå…¥è¡¨æ˜¯å¦å°†è¯­ä¹‰ç›¸ä¼¼çš„å­—è¯ç»„åˆåˆ°ä¸€èµ·ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ayOacfWd4r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(embedding, valid_size=16, valid_window=100, device='cpu'):\n",
        "    \"\"\" Returns the cosine similarity of validation words with words in the embedding matrix.\n",
        "        Here, embedding should be a PyTorch embedding module.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Here we're calculating the cosine similarity between some random words and \n",
        "    # our embedding vectors. With the similarities, we can look at what words are\n",
        "    # close to our random words.\n",
        "    \n",
        "    # sim = (a . b) / |a||b|\n",
        "    \n",
        "    embed_vectors = embedding.weight\n",
        "    \n",
        "    # magnitude of embedding vectors, |b|\n",
        "    magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
        "    \n",
        "    # pick N words from our ranges (0,window) and (1000,1000+window). lower id implies more frequent \n",
        "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
        "    valid_examples = np.append(valid_examples,\n",
        "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
        "    valid_examples = torch.LongTensor(valid_examples).to(device)\n",
        "    \n",
        "    valid_vectors = embedding(valid_examples)\n",
        "    similarities = torch.mm(valid_vectors, embed_vectors.t())/magnitudes\n",
        "        \n",
        "    return valid_examples, similarities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8GkduJJd9RW",
        "colab_type": "text"
      },
      "source": [
        "###SkipGram æ¨¡å‹\n",
        "å®šä¹‰å¹¶è®­ç»ƒ SkipGram æ¨¡å‹ã€‚\n",
        "\n",
        "\n",
        "> ä½ éœ€è¦å®šä¹‰ä¸€ä¸ªåµŒå…¥å±‚å’Œä¸€ä¸ªæœ€ç»ˆ softmax è¾“å‡ºå±‚ã€‚\n",
        "\n",
        "\n",
        "åµŒå…¥å±‚æœ‰å¤šä¸ªå‚æ•°ï¼Œæœ€é‡è¦çš„æ˜¯ï¼š\n",
        "\n",
        "\n",
        "*   num_embeddings â€“ åµŒå…¥å­—å…¸çš„å¤§å°ï¼Œå³åµŒå…¥æƒé‡çŸ©é˜µçš„è¡Œæ•°\n",
        "*   embedding_dim â€“ æ¯ä¸ªåµŒå…¥å‘é‡çš„å¤§å°ï¼Œå³åµŒå…¥ç»´åº¦\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K_ILsLmeIrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed):\n",
        "        super().__init__()\n",
        "        \n",
        "        # complete this SkipGram model\n",
        "        self.embed = nn.Embedding(n_vocab, n_embed)\n",
        "        self.output = nn.Linear(n_embed, n_vocab)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # define the forward behavior\n",
        "        x = self.embed(x)\n",
        "        scores = self.output(x)\n",
        "        log_ps = self.log_softmax(scores)\n",
        "        \n",
        "        return log_ps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q3MZVN2ePF3",
        "colab_type": "text"
      },
      "source": [
        "###è®­ç»ƒ\n",
        "ä¸‹é¢æ˜¯è®­ç»ƒå¾ªç¯ï¼Œå¦‚æœæœ‰ GPU è®¾å¤‡çš„è¯ï¼Œå»ºè®®åœ¨ GPU è®¾å¤‡ä¸Šè®­ç»ƒæ¨¡å‹ã€‚\n",
        "\n",
        "**æ³¨æ„ï¼Œå› ä¸ºæˆ‘ä»¬å‘æ¨¡å‹åº”ç”¨äº† softmax å‡½æ•°ï¼Œæ‰€ä»¥ä½¿ç”¨ NLLLossï¼Œè€Œä¸æ˜¯äº¤å‰ç†µæŸå¤±ã€‚è¿™æ˜¯å› ä¸º Softmax ä¸ NLLLoss ç›¸ç»“åˆå°±ç­‰åŒäºäº¤å‰ç†µæŸå¤±ã€‚**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upe9x1nBeU-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "embedding_dim=300 # you can change, if you want\n",
        "\n",
        "model = SkipGram(len(vocab_to_int), embedding_dim).to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "print_every = 500\n",
        "steps = 0\n",
        "epochs = 5\n",
        "\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    # get input and target batches\n",
        "    for inputs, targets in get_batches(train_words, 512):\n",
        "        steps += 1\n",
        "        inputs, targets = torch.LongTensor(inputs), torch.LongTensor(targets)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        log_ps = model(inputs)\n",
        "        loss = criterion(log_ps, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if steps % print_every == 0:                  \n",
        "            # getting examples and similarities      \n",
        "            valid_examples, valid_similarities = cosine_similarity(model.embed, device=device)\n",
        "            _, closest_idxs = valid_similarities.topk(6) # topk highest similarities\n",
        "            \n",
        "            valid_examples, closest_idxs = valid_examples.to('cpu'), closest_idxs.to('cpu')\n",
        "            for ii, valid_idx in enumerate(valid_examples):\n",
        "                closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "                print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest_words))\n",
        "            print(\"...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpPEtrh3eZZI",
        "colab_type": "text"
      },
      "source": [
        "###å¯è§†åŒ–å­—è¯å‘é‡\n",
        "ä¸‹é¢æˆ‘ä»¬å°†ä½¿ç”¨ T-SNE å¯è§†åŒ–é«˜ç»´å­—è¯å‘é‡èšç±»ã€‚T-SNE å¯ä»¥å°†è¿™äº›å‘é‡æŠ•å°„åˆ°äºŒç»´ç©ºé—´é‡Œï¼ŒåŒæ—¶ä¿ç•™å±€éƒ¨ç»“æ„ã€‚è¯·å‚é˜… Christopher Olah çš„è¿™ç¯‡å¸–å­](http://colah.github.io/posts/2014-10-Visualizing-MNIST/)ï¼Œè¯¦ç»†äº†è§£ T-SNE ä»¥åŠå¯è§†åŒ–é«˜ç»´æ•°æ®çš„å…¶ä»–æ–¹å¼ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYzW90yef9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# getting embeddings from the embedding layer of our model, by name\n",
        "embeddings = model.embed.weight.to('cpu').data.numpy()\n",
        "\n",
        "viz_words = 600\n",
        "tsne = TSNE()\n",
        "embed_tsne = tsne.fit_transform(embeddings[:viz_words, :])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 16))\n",
        "for idx in range(viz_words):\n",
        "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
        "    plt.annotate(int_to_vocab[idx], (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}